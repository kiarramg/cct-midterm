# cct-midterm
## sample info:
### In this project, I implemented a Cultural Consensus Theory (CCT) model using Bayesian inference in PyMC to estimate informant competence and group consensus on plant knowledge. The observed data consisted of binary responses from multiple informants, modeled using a hierarchical structure. Each informant’s competence (D) was assigned a Beta(2, 2) prior, favoring moderate-to-high accuracy (values between 0.5 and 1). Consensus answers for each question (Z) were treated as latent binary variables with a Bernoulli(0.5) prior, reflecting an assumption of no prior knowledge about the true answers.

### Posterior estimates revealed a range of competence scores among informants. The most competent informant (Informant 5) had an estimated competence of 0.69, while the least competent (Informant 2) had a score of 0.43. The model’s consensus answers differed from the naive majority vote on 6 out of 20 items, suggesting that the CCT model filtered out noise from lower-competence informants. However, convergence diagnostics indicated some issues: many r_hat values exceeded 1.01, and the effective sample size (ESS) was low for several parameters, particularly the binary Z variables. These issues likely stem from poor mixing of the discrete Gibbs sampler for Z. I attempted to mitigate this by increasing the number of chains and draws and setting a high target_accept rate. Future improvements could include more informative priors or alternative model parameterizations to improve mixing.